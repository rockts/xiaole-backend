from sqlalchemy import func, or_
from backend.db_setup import Memory, SessionLocal
import os
from dotenv import load_dotenv
from datetime import datetime, timedelta
from backend.semantic_search import SemanticSearchManager

load_dotenv()

# ä½¿ç”¨ç»Ÿä¸€çš„ Session å·¥å‚
Session = SessionLocal


class MemoryManager:
    def __init__(self, enable_vector_search=True):  # é»˜è®¤å¯ç”¨è¯­ä¹‰æœç´¢
        self.enable_vector_search = enable_vector_search

        # åˆå§‹åŒ–è¯­ä¹‰æœç´¢ç®¡ç†å™¨
        if self.enable_vector_search:
            try:
                self.semantic_search = SemanticSearchManager()
                print("âœ… è¯­ä¹‰æœç´¢å·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ è¯­ä¹‰æœç´¢åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œé™çº§åˆ°å…³é”®è¯æœç´¢")
                self.enable_vector_search = False
                self.semantic_search = None
        else:
            self.semantic_search = None

    def remember(
        self,
        content,
        tag="general",
        initial_importance=0.5,
        image_path=None
    ):
        """
        Store memory with importance score.

        Args:
            content: memory content
            tag: tag/category
            initial_importance: importance score (0-1) - æš‚æ—¶æœªä½¿ç”¨ï¼Œç­‰å¾…æ•°æ®åº“è¿ç§»
            image_path: å¯é€‰ï¼Œå…³è”çš„å›¾ç‰‡ç›¸å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ /uploads/images/xxx.jpgï¼‰
        """
        session = Session()
        try:
            # å»é‡æ£€æŸ¥ï¼šå¦‚æœæ˜¯ facts æ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹
            if tag == "facts":
                existing = session.query(Memory).filter(
                    Memory.tag == "facts",
                    Memory.content == content
                ).first()

                if existing:
                    print(f"âš ï¸ è·³è¿‡é‡å¤ facts: {content[:50]}")
                    return existing.id

            # å¦‚æä¾›äº† image_pathï¼Œä½† Memory æ¨¡å‹æš‚æ— è¯¥åˆ—ï¼Œåˆ™å°†å…¶å†…åµŒåˆ°å†…å®¹ä¸­
            final_content = content
            if image_path:
                prefix = f"[image_path:{image_path}]\n"
                final_content = f"{prefix}{content}" if content else prefix

            memory = Memory(
                content=final_content,
                tag=tag
                # importance_score å­—æ®µéœ€è¦æ•°æ®åº“è¿ç§»åæ‰èƒ½ä½¿ç”¨
            )
            session.add(memory)
            session.commit()

            # æ·»åŠ åˆ°è¯­ä¹‰æœç´¢ç´¢å¼•
            if self.enable_vector_search and self.semantic_search:
                try:
                    self.semantic_search.add_memory(memory.id, content, tag)
                except Exception as e:
                    print(f"æ·»åŠ è¯­ä¹‰ç´¢å¼•å¤±è´¥: {e}")

            return memory.id
        finally:
            session.close()

    def recall(self, tag="general", keyword=None, limit=None):
        """Recall memories by tag and keyword"""
        session = Session()
        try:
            # Support prefix matching for tags (case-insensitive)
            if tag:
                tag_lower = tag.lower()
                query = session.query(Memory).filter(
                    or_(
                        func.lower(Memory.tag) == tag_lower,
                        func.lower(Memory.tag).like(f"{tag_lower}:%")
                    )
                )
            else:
                query = session.query(Memory)

            # å¦‚æœæœ‰å…³é”®è¯ï¼Œè¿›è¡Œæ¨¡ç³Šæœç´¢
            if keyword:
                query = query.filter(Memory.content.contains(keyword))

            # æŒ‰æ—¶é—´å€’åº
            query = query.order_by(Memory.created_at.desc())

            # é™åˆ¶æ•°é‡
            if limit:
                query = query.limit(limit)

            memories = query.all()
            return [m.content for m in memories]
        finally:
            session.close()

    def recall_recent(self, hours=24, tag=None, limit=10):
        """Recall recent memories within specified hours"""
        session = Session()
        try:
            time_threshold = datetime.now() - timedelta(hours=hours)

            query = session.query(Memory).filter(
                Memory.created_at >= time_threshold
            )

            if tag:
                # Support prefix matching for tags (case-insensitive)
                tag_lower = tag.lower()
                print(f"DEBUG: Filtering tag with prefix: {tag_lower}")

                # Case-insensitive matching via lower() and prefix match
                # Try both exact match and prefix match
                query = query.filter(
                    or_(
                        func.lower(Memory.tag) == tag_lower,
                        func.lower(Memory.tag).like(f"{tag_lower}:%")
                    )
                )

                # Debug: Print generated SQL (best-effort)
                try:
                    compiled = query.statement.compile(
                        compile_kwargs={'literal_binds': True}
                    )
                    print(f"DEBUG SQL: {compiled}")
                except Exception:
                    pass

            query = query.order_by(Memory.created_at.desc()).limit(limit)
            memories = query.all()

            # è¿”å›å®Œæ•´å¯¹è±¡ä¿¡æ¯ï¼Œä¾›å‰ç«¯æ˜¾ç¤º
            return [{
                'id': m.id,
                'content': m.content,
                'tag': m.tag,
                'timestamp': m.created_at.strftime('%Y-%m-%d %H:%M:%S')
            } for m in memories]
        finally:
            session.close()

    def recall_by_keywords(self, keywords, tag=None, limit=10):
        """Search memories by multiple keywords with OR logic"""
        if not keywords:
            return []

        session = Session()
        try:
            # æ„å»ºå…³é”®è¯è¿‡æ»¤æ¡ä»¶
            keyword_filters = [
                Memory.content.contains(kw) for kw in keywords
            ]

            query = session.query(Memory).filter(or_(*keyword_filters))

            if tag:
                # Support prefix matching for tags (case-insensitive)
                tag_lower = tag.lower()
                query = query.filter(
                    or_(
                        func.lower(Memory.tag) == tag_lower,
                        func.lower(Memory.tag).like(f"{tag_lower}:%")
                    )
                )

            query = query.order_by(Memory.created_at.desc()).limit(limit)
            memories = query.all()

            # è¿”å›å®Œæ•´çš„è®°å¿†ä¿¡æ¯
            return [{
                'id': m.id,
                'content': m.content,
                'tag': m.tag,
                'timestamp': m.created_at.strftime('%Y-%m-%d %H:%M:%S')
            } for m in memories]
        finally:
            session.close()

    def get_stats(self):
        """Get memory statistics"""
        session = Session()
        try:
            # æ€»è®°å¿†æ•°
            total = session.query(func.count(Memory.id)).scalar()

            # æŒ‰æ ‡ç­¾ç»Ÿè®¡
            tag_stats = session.query(
                Memory.tag,
                func.count(Memory.id)
            ).group_by(Memory.tag).all()

            return {
                "total": total,
                "by_tag": {tag: count for tag, count in tag_stats}
            }
        finally:
            session.close()

    def semantic_recall(self, query, tag=None, limit=10, min_score=0.15):
        """Semantic search using TF-IDF and cosine similarity"""
        if not self.enable_vector_search or not self.semantic_search:
            # é™çº§åˆ°å…³é”®è¯æœç´¢
            print("âš ï¸ è¯­ä¹‰æœç´¢ä¸å¯ç”¨ï¼Œä½¿ç”¨å…³é”®è¯æœç´¢")
            keywords = query.split()
            return self.recall_by_keywords(keywords, tag=tag, limit=limit)

        session = Session()
        try:
            # æŸ¥è¯¢æ‰€æœ‰è®°å¿†
            query_obj = session.query(Memory)
            if tag:
                # Support prefix matching for tags (case-insensitive)
                tag_lower = tag.lower()
                query_obj = query_obj.filter(
                    or_(
                        func.lower(Memory.tag) == tag_lower,
                        func.lower(Memory.tag).like(f"{tag_lower}:%")
                    )
                )

            all_memories = query_obj.all()

            if not all_memories:
                return []

            # æ„å»ºæ–‡æ¡£åˆ—è¡¨ï¼š(id, content)
            documents = [(m.id, m.content) for m in all_memories]

            # æ‰§è¡Œè¯­ä¹‰æœç´¢
            results = self.semantic_search.search(
                query=query,
                documents=documents,
                top_k=limit,
                min_score=min_score
            )

            if not results:
                return []

            # è·å–åŒ¹é…çš„è®°å¿†è¯¦æƒ…
            result_ids = [mem_id for mem_id, _ in results]
            id_to_score = {mem_id: score for mem_id, score in results}

            matched_memories = session.query(Memory).filter(
                Memory.id.in_(result_ids)
            ).all()

            # v0.6.0: æ›´æ–°è®¿é—®è®°å½• (éœ€è¦æ•°æ®åº“è¿ç§»åå¯ç”¨)
            # for mem in matched_memories:
            #     self._update_access(mem.id)

            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›
            memories_with_scores = [
                {
                    'id': m.id,
                    'content': m.content,
                    'tag': m.tag,
                    'timestamp': m.created_at.strftime('%Y-%m-%d %H:%M:%S'),
                    'score': id_to_score.get(m.id, 0)
                }
                for m in matched_memories
            ]

            # æŒ‰åˆ†æ•°é™åºæ’åº
            memories_with_scores.sort(key=lambda x: x['score'], reverse=True)

            return memories_with_scores

        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰æœç´¢å¤±è´¥: {e}ï¼Œé™çº§åˆ°å…³é”®è¯æœç´¢")
            keywords = query.split()
            return self.recall_by_keywords(keywords, tag=tag, limit=limit)
        finally:
            session.close()

    # v0.6.0 Phase 3æ–¹æ³•: éœ€è¦æ•°æ®åº“è¿ç§»åå¯ç”¨
    # def _update_access(self, memory_id):
    #     """æ›´æ–°è®°å¿†è®¿é—®è®°å½•"""
    #     mem = self.session.query(Memory).filter(
    #         Memory.id == memory_id
    #     ).first()
    #     if mem:
    #         mem.access_count = (mem.access_count or 0) + 1
    #         mem.last_accessed_at = datetime.now()
    #         self.session.commit()
    #
    # def calculate_importance(self, memory_id):
    #     """è®¡ç®—è®°å¿†çš„é‡è¦æ€§åˆ†æ•°"""
    #     ...
    #
    # def update_all_importance_scores(self):
    #     """æ‰¹é‡æ›´æ–°æ‰€æœ‰è®°å¿†çš„é‡è¦æ€§åˆ†æ•°"""
    #     ...
    #
    # def get_top_memories(self, limit=20, tag=None):
    #     """è·å–æœ€é‡è¦çš„è®°å¿†"""
    #     ...
    #
    # def auto_archive_low_importance(self, threshold=0.1, min_age_days=30):
    #     """è‡ªåŠ¨å½’æ¡£ä½é‡è¦æ€§è®°å¿†"""
    #     ...

    def calculate_importance(self, memory_id):
        """
        v0.6.0: è®¡ç®—è®°å¿†çš„é‡è¦æ€§åˆ†æ•°

        è€ƒè™‘å› ç´ :
        1. è®¿é—®é¢‘ç‡ (40 %)
        2. æ—¶é—´è¡°å‡ (30 %)
        3. æ ‡ç­¾ç±»å‹ (30 %)

        Returns:
            float: é‡è¦æ€§åˆ†æ•°(0-1)
        """
        session = Session()
        try:
            mem = session.query(Memory).filter(
                Memory.id == memory_id
            ).first()

            if not mem:
                return 0.0

            # 1. è®¿é—®é¢‘ç‡åˆ†æ•° (0-1)
            # è®¿é—®æ¬¡æ•°è¶Šå¤šè¶Šé‡è¦ï¼Œä½¿ç”¨å¯¹æ•°å‡½æ•°é¿å…çº¿æ€§å¢é•¿
            import math
            access_score = min(
                math.log(mem.access_count + 1) / math.log(100),
                1.0
            )

            # 2. æ—¶é—´è¡°å‡åˆ†æ•° (0-1)
            # æœ€è¿‘çš„è®°å¿†æ›´é‡è¦ï¼Œä½¿ç”¨æŒ‡æ•°è¡°å‡
            days_ago = (datetime.now() - mem.created_at).days
            time_score = math.exp(-days_ago / 30.0)  # 30å¤©åŠè¡°æœŸ

            # 3. æ ‡ç­¾æƒé‡ (0-1)
            tag_weights = {
                'facts': 1.0,      # ç”¨æˆ·æ˜ç¡®å‘ŠçŸ¥çš„äº‹å®æœ€é‡è¦
                'task': 0.8,       # ä»»åŠ¡è®°å½•æ¬¡é‡è¦
                'general': 0.5,    # æ™®é€šå¯¹è¯ä¸­ç­‰é‡è¦
                'system': 0.3      # ç³»ç»Ÿæ—¥å¿—è¾ƒä¸é‡è¦
            }
            tag_score = tag_weights.get(mem.tag, 0.5)

            # Weighted average calculation
            importance = (
                access_score * 0.4 +
                time_score * 0.3 +
                tag_score * 0.3
            )

            # æ›´æ–°æ•°æ®åº“
            mem.importance_score = importance
            session.commit()

            return importance
        finally:
            session.close()

    def update_all_importance_scores(self):
        """
        v0.6.0: æ‰¹é‡æ›´æ–°æ‰€æœ‰è®°å¿†çš„é‡è¦æ€§åˆ†æ•°

        Returns:
            int: æ›´æ–°çš„è®°å¿†æ•°é‡
        """
        session = Session()
        try:
            all_memories = session.query(Memory).filter(
                Memory.is_archived == False  # noqa: E712
            ).all()

            updated_count = 0
            # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨äº† self.calculate_importanceï¼Œå®ƒå†…éƒ¨ä¹Ÿä¼šåˆ›å»º Session
            # ä¸ºäº†é¿å…åµŒå¥— Session é—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥é‡æ„ calculate_importance æˆ–è€…åœ¨è¿™é‡Œç›´æ¥è®¡ç®—
            # ä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å…ˆè·å– ID åˆ—è¡¨ï¼Œç„¶åé€ä¸ªè°ƒç”¨
            memory_ids = [m.id for m in all_memories]
        finally:
            session.close()

        for mem_id in memory_ids:
            self.calculate_importance(mem_id)
            updated_count += 1

        print(f"âœ… å·²æ›´æ–° {updated_count} æ¡è®°å¿†çš„é‡è¦æ€§åˆ†æ•°")
        return updated_count

    def get_top_memories(self, limit=20, tag=None):
        """
        v0.6.0: è·å–æœ€é‡è¦çš„è®°å¿†

        Args:
            limit: è¿”å›æ•°é‡
            tag: å¯é€‰æ ‡ç­¾è¿‡æ»¤

        Returns:
            [{content, tag, importance_score, access_count}]
        """
        session = Session()
        try:
            query = session.query(Memory).filter(
                Memory.is_archived == False  # noqa: E712
            )

            if tag:
                query = query.filter(Memory.tag == tag)

            query = query.order_by(
                Memory.importance_score.desc()
            ).limit(limit)

            memories = query.all()

            return [{
                'content': m.content,
                'tag': m.tag,
                'importance_score': m.importance_score,
                'access_count': m.access_count,
                'created_at': m.created_at.strftime('%Y-%m-%d %H:%M:%S')
            } for m in memories]
        finally:
            session.close()

    def auto_archive_low_importance(self, threshold=0.1, min_age_days=30):
        """
        v0.6.0: è‡ªåŠ¨å½’æ¡£ä½é‡è¦æ€§è®°å¿†

        å½’æ¡£ç­–ç•¥:
        - é‡è¦æ€§åˆ†æ•° < threshold
        - åˆ›å»ºæ—¶é—´ > min_age_days å¤©
        - è®¿é—®æ¬¡æ•° <= 1

        Args:
            threshold: importance threshold (0-1)
            min_age_days: minimum age in days

        Returns:
            int: archived count
        """
        from datetime import timedelta
        session = Session()
        try:
            cutoff_date = datetime.now() - timedelta(days=min_age_days)

            # æŸ¥æ‰¾éœ€è¦å½’æ¡£çš„è®°å¿†
            low_importance_memories = session.query(Memory).filter(
                Memory.is_archived == False,  # noqa: E712
                Memory.importance_score < threshold,
                Memory.created_at < cutoff_date,
                Memory.access_count <= 1
            ).all()

            archived_count = 0
            for mem in low_importance_memories:
                mem.is_archived = True
                archived_count += 1

            session.commit()

            if archived_count > 0:
                print(f"âœ… å·²å½’æ¡£ {archived_count} æ¡ä½é‡è¦æ€§è®°å¿†")

            return archived_count
        finally:
            session.close()

    def get_memory_stats(self):
        """Get memory statistics with importance analysis"""
        session = Session()
        try:
            # åŸºç¡€ç»Ÿè®¡
            total = session.query(func.count(Memory.id)).scalar()
            archived = session.query(func.count(Memory.id)).filter(
                Memory.is_archived == True  # noqa: E712
            ).scalar()
            active = total - archived

            # æŒ‰æ ‡ç­¾ç»Ÿè®¡
            tag_stats = session.query(
                Memory.tag,
                func.count(Memory.id)
            ).filter(
                Memory.is_archived == False  # noqa: E712
            ).group_by(Memory.tag).all()

            # é‡è¦æ€§åˆ†å¸ƒ
            high_importance = session.query(func.count(Memory.id)).filter(
                Memory.is_archived == False,  # noqa: E712
                Memory.importance_score >= 0.7
            ).scalar()

            medium_importance = session.query(func.count(Memory.id)).filter(
                Memory.is_archived == False,  # noqa: E712
                Memory.importance_score >= 0.3,
                Memory.importance_score < 0.7
            ).scalar()

            low_importance = session.query(func.count(Memory.id)).filter(
                Memory.is_archived == False,  # noqa: E712
                Memory.importance_score < 0.3
            ).scalar()

            return {
                "total": total,
                "active": active,
                "archived": archived,
                "by_tag": {tag: count for tag, count in tag_stats},
                "importance_distribution": {
                    "high (â‰¥0.7)": high_importance,
                    "medium (0.3-0.7)": medium_importance,
                    "low (<0.3)": low_importance
                }
            }
        finally:
            session.close()

    def cleanup_old_conversations(self, days=7):
        """
        æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„ conversation è®°å¿†

        Args:
            days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤7å¤©

        Returns:
            åˆ é™¤çš„è®°å¿†æ•°é‡
        """
        session = Session()
        try:
            cutoff_date = datetime.now() - timedelta(days=days)

            old_conversations = session.query(Memory).filter(
                Memory.tag.like('conversation:%'),
                Memory.created_at < cutoff_date
            ).all()

            count = len(old_conversations)
            for mem in old_conversations:
                session.delete(mem)

            session.commit()
            print(f"ğŸ—‘ï¸ æ¸…ç†äº† {count} æ¡è¶…è¿‡{days}å¤©çš„conversationè®°å¿†")
            return count
        finally:
            session.close()
