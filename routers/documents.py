from fastapi import APIRouter, Depends, UploadFile, File, HTTPException
from typing import Dict, Any, Optional
import os
import time
import json
from dependencies import get_xiaole_agent
from agent import XiaoLeAgent
from document_summarizer import DocumentSummarizer
from config import UPLOADS_DIR, DB_CONFIG
from auth import get_current_user

router = APIRouter(
    prefix="/documents",
    tags=["documents"]
)

# åˆå§‹åŒ–æ–‡æ¡£æ€»ç»“å™¨
document_summarizer = DocumentSummarizer(
    db_config=DB_CONFIG,
    upload_dir=UPLOADS_DIR
)


def get_agent():
    return get_xiaole_agent()


@router.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = "default_user",
    session_id: Optional[str] = None,
    current_user: str = Depends(get_current_user),
    agent: XiaoLeAgent = Depends(get_agent)
):
    """
    ä¸Šä¼ æ–‡æ¡£å¹¶è‡ªåŠ¨æ€»ç»“
    """
    user_id = current_user
    start_time = time.time()
    doc_id = None

    try:
        # éªŒè¯æ–‡ä»¶
        file_content = await file.read()
        file_size = len(file_content)

        valid, file_type, error_msg = document_summarizer.validate_file(
            file.filename, file_size
        )

        if not valid:
            return {
                "success": False,
                "error": error_msg
            }

        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp = int(time.time())
        safe_filename = f"{timestamp}_{file.filename}"

        # ç¡®ä¿ documents å­ç›®å½•å­˜åœ¨
        docs_dir = os.path.join(UPLOADS_DIR, "documents")
        if not os.path.exists(docs_dir):
            os.makedirs(docs_dir, exist_ok=True)

        file_path = os.path.join(docs_dir, safe_filename)

        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'wb') as f:
            f.write(file_content)

        # åˆ›å»ºæ•°æ®åº“è®°å½•
        doc_id = document_summarizer.create_document_record(
            user_id=user_id,
            session_id=session_id or "",
            filename=safe_filename,
            original_filename=file.filename,
            file_type=file_type,
            file_size=file_size,
            file_path=file_path
        )

        # æå–æ–‡æœ¬
        try:
            content = document_summarizer.extract_text(file_path, file_type)
            chunks = document_summarizer.split_text(content)

            # æ›´æ–°å†…å®¹
            document_summarizer.update_document_content(
                doc_id, content, len(chunks)
            )

            # ç”Ÿæˆæ€»ç»“
            if len(chunks) == 1:
                summary = document_summarizer.summarize_chunk(
                    chunks[0],
                    agent._call_deepseek
                )
            else:
                chunk_summaries = []
                for i, chunk in enumerate(chunks):
                    chunk_summary = document_summarizer.summarize_chunk(
                        chunk,
                        agent._call_deepseek
                    )
                    chunk_summaries.append(chunk_summary)

                combined_text = "\n\n".join(chunk_summaries)
                if len(combined_text) > 4000:
                    summary = document_summarizer.summarize_chunk(
                        combined_text,
                        agent._call_deepseek
                    )
                else:
                    summary = combined_text

            # æå–å…³é”®è¦ç‚¹
            key_points = document_summarizer.extract_key_points(
                content,
                agent._call_deepseek
            )

            # æ›´æ–°æ€»ç»“ç»“æœ
            processing_time = time.time() - start_time
            document_summarizer.update_document_summary(
                doc_id, summary, key_points, processing_time
            )

            # å­˜å…¥è®°å¿†
            try:
                key_points_list = key_points if isinstance(
                    key_points, list) else []
                key_points_str = "\n".join([f"- {p}" for p in key_points_list])

                memory_content = (
                    f"ã€æ–‡æ¡£çŸ¥è¯†ã€‘ç”¨æˆ·ä¸Šä¼ äº†æ–‡æ¡£ã€Š{file.filename}ã€‹\n"
                    f"æ–‡æ¡£æ€»ç»“ï¼š\n{summary}\n\n"
                    f"å…³é”®è¦ç‚¹ï¼š\n{key_points_str}"
                )

                agent.memory.remember(
                    content=memory_content,
                    tag=f"document:{file.filename}"
                )

                # ä¿å­˜å¯¹è¯è®°å½•
                target_session_id = session_id
                if not target_session_id:
                    target_session_id = agent.conversation.create_session(
                        user_id=user_id,
                        title=f"æ–‡æ¡£æ€»ç»“ï¼š{file.filename}"
                    )

                agent.conversation.add_message(
                    session_id=target_session_id,
                    role="user",
                    content=f"ğŸ“„ ä¸Šä¼ æ–‡æ¡£ï¼š{file.filename}"
                )

                ai_content = f"### ğŸ“„ æ–‡æ¡£æ€»ç»“ï¼š{file.filename}\n\n{summary}\n\n#### ğŸ’¡ å…³é”®è¦ç‚¹\n{key_points_str}"
                agent.conversation.add_message(
                    session_id=target_session_id,
                    role="assistant",
                    content=ai_content
                )

            except Exception as e:
                print(f"âš ï¸ æ–‡æ¡£è®°å¿†/å¯¹è¯å­˜å‚¨å¤±è´¥: {e}")

            return {
                "success": True,
                "document_id": doc_id,
                "session_id": target_session_id,
                "summary": summary,
                "key_points": key_points,
                "processing_time": processing_time,
                "content_length": len(content),
                "chunk_count": len(chunks)
            }

        except Exception as e:
            if doc_id:
                document_summarizer.mark_document_failed(doc_id, str(e))
            raise

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@router.get("/{doc_id}")
def get_document_detail(doc_id: int):
    """è·å–æ–‡æ¡£è¯¦æƒ…"""
    try:
        doc = document_summarizer.get_document(doc_id)
        if not doc:
            return {
                "success": False,
                "error": "æ–‡æ¡£ä¸å­˜åœ¨"
            }

        return {
            "success": True,
            "document": doc
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@router.get("/{doc_id}/export")
def export_document(doc_id: int, format: str = "md"):
    """å¯¼å‡ºæ–‡æ¡£æ€»ç»“"""
    try:
        doc = document_summarizer.get_document(doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

        content = f"""# {doc['filename']}

## æ–‡æ¡£ä¿¡æ¯
- æ–‡ä»¶å¤§å°: {doc['file_size'] / 1024:.2f} KB
- å¤„ç†æ—¶é—´: {doc['processing_time']:.1f}ç§’
- åˆ†å—æ•°é‡: {doc['chunk_count']}

## å…³é”®è¦ç‚¹

"""
        key_points = doc.get('key_points', [])
        if isinstance(key_points, str):
            try:
                key_points = json.loads(key_points)
            except Exception:
                key_points = []

        for i, point in enumerate(key_points, 1):
            content += f"{i}. {point}\n"

        content += f"\n## æ™ºèƒ½æ€»ç»“\n\n{doc['summary']}\n"

        from fastapi.responses import Response
        from urllib.parse import quote

        filename = f"{doc['original_filename']}_summary.md"
        encoded_filename = quote(filename)

        return Response(
            content=content,
            media_type="text/markdown",
            headers={
                "Content-Disposition": f"attachment; filename*=utf-8''{encoded_filename}"
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/users/{user_id}")
def get_user_documents(
    user_id: str,
    status: Optional[str] = None,
    limit: int = 50
):
    """è·å–ç”¨æˆ·çš„æ–‡æ¡£åˆ—è¡¨"""
    try:
        docs = document_summarizer.get_user_documents(
            user_id, status, limit
        )

        return {
            "success": True,
            "documents": docs,
            "count": len(docs)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@router.delete("/{doc_id}")
def delete_document(doc_id: int):
    """åˆ é™¤æ–‡æ¡£"""
    try:
        success = document_summarizer.delete_document(doc_id)
        return {
            "success": success
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/admin/migrate_documents")
def migrate_documents(
    from_user: str = "default_user",
    to_user: str = "admin"
):
    """ç®¡ç†å‘˜æ¥å£:è¿ç§»æ–‡æ¡£ä»ä¸€ä¸ªç”¨æˆ·åˆ°å¦ä¸€ä¸ªç”¨æˆ·"""
    import psycopg2
    from config import DB_CONFIG

    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # ç»Ÿè®¡éœ€è¦è¿ç§»çš„æ•°é‡
        cur.execute(
            "SELECT COUNT(*) FROM documents WHERE user_id = %s",
            (from_user,)
        )
        count = cur.fetchone()[0]

        if count == 0:
            cur.close()
            conn.close()
            return {"migrated": 0, "message": "æ— éœ€è¿ç§»"}

        # æ‰§è¡Œè¿ç§»
        cur.execute(
            "UPDATE documents SET user_id = %s WHERE user_id = %s",
            (to_user, from_user)
        )
        conn.commit()
        cur.close()
        conn.close()

        return {
            "migrated": count,
            "message": f"æˆåŠŸè¿ç§» {count} ä¸ªæ–‡æ¡£ä» {from_user} åˆ° {to_user}"
        }
    except Exception as e:
        return {"error": str(e), "migrated": 0}
