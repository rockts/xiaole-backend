<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯­éŸ³æŒ‰é’®æµ‹è¯•</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 40px;
            max-width: 800px;
            margin: 0 auto;
        }

        .test-section {
            margin: 20px 0;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 5px;
            cursor: pointer;
        }

        .voice-btn {
            font-size: 24px;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: #4CAF50;
            color: white;
            border: none;
        }

        .voice-btn.recording {
            background: #f44336;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {

            0%,
            100% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.1);
            }
        }

        #status {
            margin-top: 20px;
            padding: 10px;
            background: #f5f5f5;
            border-radius: 4px;
        }

        .log {
            margin-top: 10px;
            padding: 10px;
            background: #000;
            color: #0f0;
            font-family: monospace;
            font-size: 12px;
            max-height: 300px;
            overflow-y: auto;
        }
    </style>
</head>

<body>
    <h1>ğŸ¤ è¯­éŸ³æŒ‰é’®è¯Šæ–­å·¥å…·</h1>

    <div class="test-section">
        <h2>æµ‹è¯• 1: ç®€å•ç‚¹å‡»æµ‹è¯•</h2>
        <button onclick="testClick()">ç‚¹å‡»æˆ‘</button>
        <p id="clickResult">æœªç‚¹å‡»</p>
    </div>

    <div class="test-section">
        <h2>æµ‹è¯• 2: éº¦å…‹é£æƒé™</h2>
        <button onclick="testMicrophone()">æµ‹è¯•éº¦å…‹é£æƒé™</button>
        <p id="micResult">æœªæµ‹è¯•</p>
        <div id="micList" style="margin-top:10px;"></div>
    </div>

    <div class="test-section">
        <h2>æµ‹è¯• 3: ç™¾åº¦è¯­éŸ³æœåŠ¡</h2>
        <button onclick="testBaiduService()">æ£€æŸ¥æœåŠ¡çŠ¶æ€</button>
        <p id="serviceResult">æœªæµ‹è¯•</p>
    </div>

    <div class="test-section">
        <h2>æµ‹è¯• 4: å®Œæ•´å½•éŸ³æµç¨‹</h2>
        <button class="voice-btn" id="testVoiceBtn" onclick="testFullRecording()">ğŸ¤</button>
        <div id="status">çŠ¶æ€: å°±ç»ª</div>
        <canvas id="waveform" width="700" height="100" style="background:#000;margin-top:10px;"></canvas>
        <p id="volumeInfo" style="margin-top:10px;color:#666;">éŸ³é‡: -</p>
    </div>

    <div class="log" id="log"></div>

    <script>
        function log(message) {
            const logDiv = document.getElementById('log');
            const time = new Date().toLocaleTimeString();
            logDiv.innerHTML += `[${time}] ${message}<br>`;
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(message);
        }

        function testClick() {
            document.getElementById('clickResult').textContent = 'âœ… ç‚¹å‡»æˆåŠŸï¼æŒ‰é’®å·¥ä½œæ­£å¸¸';
            log('âœ… ç®€å•ç‚¹å‡»æµ‹è¯•é€šè¿‡');
        }

        async function testMicrophone() {
            log('ğŸ” æµ‹è¯•éº¦å…‹é£æƒé™...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                document.getElementById('micResult').textContent = 'âœ… éº¦å…‹é£æƒé™å·²è·å–';
                log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸ');

                // åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è¾“å…¥è®¾å¤‡
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputs = devices.filter(d => d.kind === 'audioinput');

                let html = '<p><strong>å¯ç”¨éº¦å…‹é£:</strong></p><ul style="text-align:left;">';
                audioInputs.forEach((device, i) => {
                    html += `<li>${i + 1}. ${device.label || 'éº¦å…‹é£ ' + (i + 1)} (ID: ${device.deviceId.substring(0, 20)}...)</li>`;
                    log(`  éº¦å…‹é£ ${i + 1}: ${device.label || 'æœªå‘½å'}`);
                });
                html += '</ul><p style="color:#666;font-size:12px;">æç¤º: å¦‚æœè¯†åˆ«ä¸å‡†ï¼Œå¯èƒ½æ˜¯æµè§ˆå™¨é€‰æ‹©äº†é”™è¯¯çš„éº¦å…‹é£</p>';
                document.getElementById('micList').innerHTML = html;

                stream.getTracks().forEach(track => track.stop());
            } catch (error) {
                document.getElementById('micResult').textContent = `âŒ é”™è¯¯: ${error.name} - ${error.message}`;
                log(`âŒ éº¦å…‹é£æƒé™å¤±è´¥: ${error.name}`);
            }
        }

        async function testBaiduService() {
            log('ğŸ” æ£€æŸ¥ç™¾åº¦è¯­éŸ³æœåŠ¡...');
            try {
                const response = await fetch('/api/voice/status?detailed=true');
                const result = await response.json();
                document.getElementById('serviceResult').textContent =
                    `æœåŠ¡çŠ¶æ€: ${result.enabled ? 'âœ… å·²å¯ç”¨' : 'âŒ æœªå¯ç”¨'}\né…ç½®: ${JSON.stringify(result, null, 2)}`;
                log(`âœ… æœåŠ¡çŠ¶æ€: ${JSON.stringify(result)}`);
            } catch (error) {
                document.getElementById('serviceResult').textContent = `âŒ é”™è¯¯: ${error.message}`;
                log(`âŒ æœåŠ¡æ£€æŸ¥å¤±è´¥: ${error.message}`);
            }
        }

        let isRecording = false;
        let recorder = null;
        let animationId = null;
        let volumeCheckInterval = null;

        function monitorVolume(stream, analyser) {
            const canvas = document.getElementById('waveform');
            const ctx = canvas.getContext('2d');
            const bufferLength = analyser.fftSize;
            const dataArray = new Uint8Array(bufferLength);

            function updateVolume() {
                if (!isRecording) {
                    cancelAnimationFrame(animationId);
                    if (volumeCheckInterval) {
                        clearInterval(volumeCheckInterval);
                        volumeCheckInterval = null;
                    }
                    return;
                }

                animationId = requestAnimationFrame(updateVolume);

                // è·å–æ—¶åŸŸæ•°æ®
                analyser.getByteTimeDomainData(dataArray);

                // ç»˜åˆ¶æ³¢å½¢
                ctx.fillStyle = '#000';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                ctx.lineWidth = 2;
                ctx.strokeStyle = '#0f0';
                ctx.beginPath();

                const sliceWidth = canvas.width / bufferLength;
                let x = 0;

                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i] / 128.0;
                    const y = v * canvas.height / 2;
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                    x += sliceWidth;
                }

                ctx.lineTo(canvas.width, canvas.height / 2);
                ctx.stroke();

                // è®¡ç®—éŸ³é‡ (ä½¿ç”¨ Byte æ•°æ®)
                let sum = 0;
                let max = 0;
                let min = 255;

                for (let i = 0; i < bufferLength; i++) {
                    const value = dataArray[i];
                    if (value > max) max = value;
                    if (value < min) min = value;
                    const diff = Math.abs(value - 128);
                    sum += diff * diff;
                }

                // å³°å€¼å·®å¼‚
                const peakDiff = max - min;
                const peakPercent = Math.round((peakDiff / 255) * 100);

                // RMS
                const rms = Math.sqrt(sum / bufferLength) / 128;
                const rmsPercent = Math.round(rms * 100);

                let statusText = '';
                if (peakPercent < 5) {
                    statusText = 'âš ï¸ å‡ ä¹æ²¡å£°éŸ³ï¼';
                } else if (peakPercent < 15) {
                    statusText = 'âš ï¸ å¤ªå°äº†ï¼';
                } else if (peakPercent < 30) {
                    statusText = 'âš ï¸ æœ‰ç‚¹å°';
                } else if (peakPercent < 70) {
                    statusText = 'âœ… éŸ³é‡æ­£å¸¸';
                } else {
                    statusText = 'âœ… éŸ³é‡å¾ˆå¥½ï¼';
                }

                document.getElementById('volumeInfo').textContent =
                    `å³°å€¼: ${peakPercent}% | RMS: ${rmsPercent}% ${statusText} [Raw: ${min}-${max}]`;
            }

            updateVolume();
        }

        function drawWaveform(analyser) {
            // è¿™ä¸ªå‡½æ•°ç°åœ¨ç”± monitorVolume æ›¿ä»£
        }

        async function testFullRecording() {
            const btn = document.getElementById('testVoiceBtn');
            const status = document.getElementById('status');

            if (isRecording) {
                log('â¹ï¸ åœæ­¢å½•éŸ³...');
                isRecording = false;
                btn.classList.remove('recording');
                status.textContent = 'çŠ¶æ€: å¤„ç†ä¸­...';

                // æ¸…ç©ºæ³¢å½¢
                const canvas = document.getElementById('waveform');
                const ctx = canvas.getContext('2d');
                ctx.fillStyle = '#000';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                document.getElementById('volumeInfo').textContent = 'éŸ³é‡: -';

                if (recorder) {
                    // åœæ­¢å½•éŸ³æµ
                    recorder.stream.getTracks().forEach(track => track.stop());
                    recorder.processor.disconnect();
                    recorder.source.disconnect();

                    // åˆå¹¶éŸ³é¢‘æ•°æ®å¹¶å¢ç›Š
                    const raw = mergeBuffers(recorder.bufferL);
                    const boosted = normalizeAndBoost(raw); // å¢ç›Šå¤„ç†
                    const downsampled = downsampleBuffer(boosted, recorder.audioContext.sampleRate, 16000);
                    const wavBlob = encodeWAV(downsampled, 16000);

                    log(`ğŸ“¦ éŸ³é¢‘æ•°æ®: ${wavBlob.size} å­—èŠ‚`);

                    // ä¸Šä¼ è¯†åˆ«
                    const formData = new FormData();
                    formData.append('file', wavBlob, 'test.wav');

                    try {
                        const response = await fetch('/api/voice/recognize', {
                            method: 'POST',
                            body: formData
                        });
                        const result = await response.json();

                        if (result.success) {
                            status.textContent = `âœ… è¯†åˆ«æˆåŠŸ: ${result.text}`;
                            log(`âœ… è¯†åˆ«ç»“æœ: ${result.text}`);
                        } else {
                            status.textContent = `âŒ è¯†åˆ«å¤±è´¥: ${result.error}`;
                            log(`âŒ è¯†åˆ«å¤±è´¥: ${result.error}`);
                        }
                    } catch (error) {
                        status.textContent = `âŒ ä¸Šä¼ å¤±è´¥: ${error.message}`;
                        log(`âŒ ä¸Šä¼ å¤±è´¥: ${error.message}`);
                    }
                }

                status.textContent = 'çŠ¶æ€: å°±ç»ª';
                return;
            }

            // å¼€å§‹å½•éŸ³
            try {
                log('ğŸ¤ å¼€å§‹å½•éŸ³...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                isRecording = true;
                btn.classList.add('recording');
                status.textContent = 'çŠ¶æ€: å½•éŸ³ä¸­...ï¼ˆç‚¹å‡»åœæ­¢ï¼‰';

                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                analyser.smoothingTimeConstant = 0.8;

                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                const bufferL = [];

                processor.onaudioprocess = function (e) {
                    if (!isRecording) return;
                    const channel = e.inputBuffer.getChannelData(0);
                    bufferL.push(new Float32Array(channel));
                };

                // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
                source.connect(analyser);
                source.connect(processor);
                processor.connect(audioContext.destination);

                recorder = { audioContext, source, processor, stream, bufferL, analyser };
                log('âœ… å½•éŸ³å·²å¯åŠ¨');
                log(`  é‡‡æ ·ç‡: ${audioContext.sampleRate} Hz`);
                log(`  FFTå¤§å°: ${analyser.fftSize}`);

                // å¼€å§‹ç›‘æ§éŸ³é‡
                monitorVolume(stream, analyser);

            } catch (error) {
                status.textContent = `âŒ é”™è¯¯: ${error.message}`;
                log(`âŒ å¯åŠ¨å½•éŸ³å¤±è´¥: ${error.name} - ${error.message}`);
            }
        }

        // è¾…åŠ©å‡½æ•°
        function mergeBuffers(bufferArray) {
            let length = 0;
            bufferArray.forEach(b => length += b.length);
            const result = new Float32Array(length);
            let offset = 0;
            bufferArray.forEach(b => { result.set(b, offset); offset += b.length; });
            return result;
        }

        // éŸ³é¢‘å½’ä¸€åŒ–å’Œå¢ç›Š
        function normalizeAndBoost(buffer, targetPeak = 0.95, minGain = 2.0) {
            // æ‰¾åˆ°æœ€å¤§æŒ¯å¹…
            let max = 0;
            for (let i = 0; i < buffer.length; i++) {
                const abs = Math.abs(buffer[i]);
                if (abs > max) max = abs;
            }

            // è®¡ç®—å¢ç›Š
            let gain = 1.0;
            if (max > 0) {
                gain = Math.max(targetPeak / max, minGain);
            } else {
                gain = minGain;
            }

            // é™åˆ¶æœ€å¤§å¢ç›Š
            gain = Math.min(gain, 10.0);

            log(`ğŸ”Š éŸ³é¢‘å¢ç›Š: ${gain.toFixed(2)}x (åŸå§‹å³°å€¼: ${(max * 100).toFixed(1)}%)`);

            // åº”ç”¨å¢ç›Š
            const result = new Float32Array(buffer.length);
            for (let i = 0; i < buffer.length; i++) {
                result[i] = Math.max(-1, Math.min(1, buffer[i] * gain));
            }

            return result;
        }

        function downsampleBuffer(buffer, inSampleRate, outSampleRate) {
            if (outSampleRate === inSampleRate) return buffer;
            const ratio = inSampleRate / outSampleRate;
            const newLength = Math.round(buffer.length / ratio);
            const result = new Float32Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            while (offsetResult < result.length) {
                const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio);
                let accum = 0, count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }
                result[offsetResult] = accum / count;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result;
        }

        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);

            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            writeString(0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, samples.length * 2, true);

            let offset = 44;
            for (let i = 0; i < samples.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }

            return new Blob([view], { type: 'audio/wav' });
        }

        log('ğŸš€ è¯Šæ–­å·¥å…·å·²åŠ è½½');
    </script>
</body>

</html>